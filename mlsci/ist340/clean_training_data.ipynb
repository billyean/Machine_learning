{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/h0y01c9/opt/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (309,312,314,317,329,332,334) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "pandemic = pd.read_csv(\"final/Confirmed cases and deaths.csv\")\n",
    "prepandemic = pd.read_csv(\"final/prepandemic_v2.csv\")\n",
    "unemployment = pd.read_csv(\"final/Unemployment_v1.csv\")\n",
    "\n",
    "# Remove all Puerto Rico data\n",
    "pandemic = pandemic.drop(pandemic[pandemic['stname'] == 'Puerto Rico'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need state and county name\n",
    "state = pandemic['stname']\n",
    "county = pandemic['ctyname']\n",
    "\n",
    "# The confirmed cases and death number is accumulated, used the last available date data\n",
    "confirmed_cases = pandemic['confirmed_cases_20200502']\n",
    "deaths = pandemic['death20200502']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        37\n",
       "1        35\n",
       "2        25\n",
       "3        30\n",
       "4        36\n",
       "5        36\n",
       "6        22\n",
       "7        34\n",
       "8        35\n",
       "9        35\n",
       "10       36\n",
       "11       31\n",
       "12       28\n",
       "13       35\n",
       "14       37\n",
       "15       26\n",
       "16       33\n",
       "17       29\n",
       "18       35\n",
       "19       31\n",
       "20       31\n",
       "21       38\n",
       "22       27\n",
       "23       32\n",
       "24       31\n",
       "25       42\n",
       "26       30\n",
       "27       32\n",
       "28       33\n",
       "29       30\n",
       "       ... \n",
       "3112     17\n",
       "3113     41\n",
       "3114     41\n",
       "3115     36\n",
       "3116     27\n",
       "3117     44\n",
       "3118     48\n",
       "3119     37\n",
       "3120     21\n",
       "3121     37\n",
       "3122     42\n",
       "3123     31\n",
       "3124     26\n",
       "3125     43\n",
       "3126     36\n",
       "3127     22\n",
       "3128     37\n",
       "3129     39\n",
       "3130     28\n",
       "3131     38\n",
       "3132     23\n",
       "3133     46\n",
       "3134    102\n",
       "3135     48\n",
       "3136     36\n",
       "3137     34\n",
       "3138     37\n",
       "3139     29\n",
       "3140     35\n",
       "3141    102\n",
       "Length: 3142, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get days between first confirmed case to now\n",
    "import datetime\n",
    "def days(pandemic_row, start = datetime.datetime(2020,1,22), end = datetime.datetime(2020,4,18), min_number = 200, min_precent=0.3):\n",
    "    end_title = 'confirmed_cases_' +  end.strftime(\"%Y%m%d\")\n",
    "    total_days = (end - start).days + 1\n",
    "    min_cases = min(pandemic_row[end_title] * min_precent, min_number)\n",
    "    current = start\n",
    "    accumulate_cases = 0\n",
    "    days = 0\n",
    "    while current <= end:\n",
    "        title = 'confirmed_cases_' +  current.strftime(\"%Y%m%d\")\n",
    "        accumulate_cases += pandemic_row[title]\n",
    "        if accumulate_cases < min_cases:\n",
    "            days += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        current += datetime.timedelta(days=1)\n",
    "    \n",
    "    return total_days - days\n",
    "case_days = pandemic.apply(lambda x: days(x,end = datetime.datetime(2020,5,2)), axis = 1) \n",
    "case_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use year 2018(closest) population density\n",
    "populationdensity=prepandemic['popdensity_2018']\n",
    "populationdensity_min = populationdensity.min()\n",
    "populationdensity_mean = populationdensity.mean()\n",
    "populationdensity_stage = populationdensity_mean - populationdensity_min\n",
    "def populationdensity_category(populationdensity):\n",
    "    if populationdensity < populationdensity_mean - populationdensity_stage * 0.9: \n",
    "        return '1_Very Low' \n",
    "    elif populationdensity < populationdensity_mean - populationdensity_stage * 0.3: \n",
    "        return '2_Low'  \n",
    "    elif populationdensity < populationdensity_mean + populationdensity_stage * 0.3: \n",
    "        return '3_Medium'   \n",
    "    elif populationdensity < populationdensity_mean + populationdensity_stage: \n",
    "        return '4_High' \n",
    "    else:\n",
    "        return 'Very_High'\n",
    "populationdensity_category = prepandemic.apply(lambda x: populationdensity_category(x['popdensity_2018']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 3 most populations ethnicity group in the county\n",
    "def ethnic_group_top(hispanic, white, black, indian, asian, hawaii_na, top):\n",
    "    ethnic_groups = [('Hispanic', hispanic), ('White', white), ('Black', black), ('Indian', indian), ('Asian', asian), ('Hawaii and N/A', hawaii_na)]\n",
    "    ethnic_groups = sorted(ethnic_groups, key = lambda x: -x[1])\n",
    "    return ethnic_groups[top - 1][0]\n",
    "\n",
    "ethnic_group_top1 = prepandemic.apply(lambda x: ethnic_group_top(x['hispanic_2018'], x['nhwhite_2018'], x['nhblack_2018'], x['nhindian_2018'], x['nhasian_2018'], x['nhhawaii_2018'], 1), axis = 1)\n",
    "ethnic_group_top2 = prepandemic.apply(lambda x: ethnic_group_top(x['hispanic_2018'], x['nhwhite_2018'], x['nhblack_2018'], x['nhindian_2018'], x['nhasian_2018'], x['nhhawaii_2018'], 2), axis = 1)\n",
    "ethnic_group_top3 = prepandemic.apply(lambda x: ethnic_group_top(x['hispanic_2018'], x['nhwhite_2018'], x['nhblack_2018'], x['nhindian_2018'], x['nhasian_2018'], x['nhhawaii_2018'], 3), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age data has 18 columns, we group them to children, young adult, middle adult, senior\n",
    "# column1:  age 0-4 prop.\n",
    "# column2:  age 5-9 prop.\n",
    "# column3:  age 10-14 prop.\n",
    "# column4:  age 15-19 prop.\n",
    "# column5:  age 20-24 prop.\n",
    "# column6:  age 25-29 prop.\n",
    "# column7:  age 30-34 prop.\n",
    "# column8:  age 35-39 prop.\n",
    "# column9:  age 40-44 prop.\n",
    "# column10: age 45-49 prop.\n",
    "# column11: age 50-54 prop.\n",
    "# column12: age 55-59 prop.\n",
    "# column13: age 60-64 prop.\n",
    "# column14: age 65-69 prop.\n",
    "# column15: age 70-74 prop.\n",
    "# column16: age 75-79 prop.\n",
    "# column17: age 80-84 prop.\n",
    "# column18: age 85+ prop.\n",
    "def age_group_top(age, top):\n",
    "    children_poportion = age[0] + age[1] + age[2] + age[3]\n",
    "    young_adult_poportion = age[4] + age[5] + age[6] + age[7] + age[8]\n",
    "    middle_adult_poportion = age[9] + age[10] + age[11] + age[12]\n",
    "    senior_poportion = age[13] + age[14] + age[15] + age[16] + age[17]\n",
    "    age_group_list = [('Children', children_poportion), ('Young Adult', young_adult_poportion), ('Middle Adult', middle_adult_poportion), ('Senior', senior_poportion)]\n",
    "    age_group_list = sorted(age_group_list, key = lambda x: -x[1])\n",
    "    return age_group_list[top - 1][0]\n",
    "age_groups_top1 = prepandemic.apply(lambda x: age_group_top([x['ageg1_2018'], x['ageg2_2018'], x['ageg3_2018'], x['ageg4_2018'], x['ageg5_2018'], x['ageg6_2018'], x['ageg7_2018'], x['ageg8_2018'], x['ageg9_2018'], x['ageg10_2018'], x['ageg11_2018'], x['ageg12_2018'], x['ageg13_2018'], x['ageg14_2018'], x['ageg15_2018'], x['ageg16_2018'], x['ageg17_2018'], x['ageg18_2018']], 1), axis = 1)\n",
    "age_groups_top2 = prepandemic.apply(lambda x: age_group_top([x['ageg1_2018'], x['ageg2_2018'], x['ageg3_2018'], x['ageg4_2018'], x['ageg5_2018'], x['ageg6_2018'], x['ageg7_2018'], x['ageg8_2018'], x['ageg9_2018'], x['ageg10_2018'], x['ageg11_2018'], x['ageg12_2018'], x['ageg13_2018'], x['ageg14_2018'], x['ageg15_2018'], x['ageg16_2018'], x['ageg17_2018'], x['ageg18_2018']], 2), axis = 1)\n",
    "age_groups_top3 = prepandemic.apply(lambda x: age_group_top([x['ageg1_2018'], x['ageg2_2018'], x['ageg3_2018'], x['ageg4_2018'], x['ageg5_2018'], x['ageg6_2018'], x['ageg7_2018'], x['ageg8_2018'], x['ageg9_2018'], x['ageg10_2018'], x['ageg11_2018'], x['ageg12_2018'], x['ageg13_2018'], x['ageg14_2018'], x['ageg15_2018'], x['ageg16_2018'], x['ageg17_2018'], x['ageg18_2018']], 3), axis = 1)\n",
    "age_groups_top4 = prepandemic.apply(lambda x: age_group_top([x['ageg1_2018'], x['ageg2_2018'], x['ageg3_2018'], x['ageg4_2018'], x['ageg5_2018'], x['ageg6_2018'], x['ageg7_2018'], x['ageg8_2018'], x['ageg9_2018'], x['ageg10_2018'], x['ageg11_2018'], x['ageg12_2018'], x['ageg13_2018'], x['ageg14_2018'], x['ageg15_2018'], x['ageg16_2018'], x['ageg17_2018'], x['ageg18_2018']], 4), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all education adata\n",
    "education = pd.read_excel(\"final/Education_By_County.xls\")\n",
    "education = education.drop(education[pd.isna(education['2013 Rural-urban Continuum Code'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In education data set[VA]: 134 rows, in pandemic dataset[Virginia]: 133 rows\n",
      "In education data set[PR]: 78 rows, in pandemic dataset[Puerto Rico]: 0 rows\n"
     ]
    }
   ],
   "source": [
    "states_map = pd.read_csv(\"final/states.csv\")\n",
    "states_map\n",
    "\n",
    "for index, row in states_map.iterrows():\n",
    "    pc = len(pandemic[pandemic['stname'] == row[1]])\n",
    "    ec = len(education[education['State'] == row[0]])\n",
    "    if pc != ec:\n",
    "        print(f\"In education data set[{row[0]}]: {ec} rows, in pandemic dataset[{row[1]}]: {pc} rows\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedford city is missing in va_pandemic\n"
     ]
    }
   ],
   "source": [
    "va_pandemic = pandemic[pandemic['stname'] == 'Virginia']\n",
    "va_education = education[education['State'] == 'VA']\n",
    "for index, row in va_education.iterrows():\n",
    "    area = row['Area name']\n",
    "    if len(va_pandemic[va_pandemic['ctyname'] == area]) == 0:\n",
    "        print(f\"{area} is missing in va_pandemic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = education.drop(education[education['Area name'] == 'Bedford city'].index)\n",
    "\n",
    "#education['Percent of adults completing some college or associate\\'s degree, 2014-18']\n",
    "# education['Percent of adults with a bachelor\\'s degree or higher, 2014-18']\n",
    "\n",
    "# Age data has 18 columns, we group them to children, young adult, middle adult, senior\n",
    "# column1:  less than high school diploma poportion.\n",
    "# column2:  high school diploma only poportion.\n",
    "# column3:  some college or associate degress poportion.\n",
    "# column4:  bachelor or higher education poportion.\n",
    "def education_group_top(less_than_high_school, high_school, college, bachelor_above, top):\n",
    "    education_group = [('Less_than_high_school', less_than_high_school), ('High_school', high_school), ('Some_college_or_associate', college), ('Bachelor_Or_Above', bachelor_above)]\n",
    "    education_group = sorted(education_group, key = lambda x: -x[1])\n",
    "    return education_group[top - 1][0]\n",
    "\n",
    "education_group_top1 = education.apply(lambda x: education_group_top(x['Percent of adults with less than a high school diploma, 2014-18'], \n",
    "                                                                     x['Percent of adults with a high school diploma only, 2014-18'], \n",
    "                                                                     x['Percent of adults completing some college or associate\\'s degree, 2014-18'], \n",
    "                                                                     x['Percent of adults with a bachelor\\'s degree or higher, 2014-18'], 1), axis=1)\n",
    "education_group_top2 = education.apply(lambda x: education_group_top(x['Percent of adults with less than a high school diploma, 2014-18'], \n",
    "                                                                     x['Percent of adults with a high school diploma only, 2014-18'], \n",
    "                                                                     x['Percent of adults completing some college or associate\\'s degree, 2014-18'], \n",
    "                                                                     x['Percent of adults with a bachelor\\'s degree or higher, 2014-18'], 2), axis=1)\n",
    "education_group_top3 = education.apply(lambda x: education_group_top(x['Percent of adults with less than a high school diploma, 2014-18'], \n",
    "                                                                     x['Percent of adults with a high school diploma only, 2014-18'], \n",
    "                                                                     x['Percent of adults completing some college or associate\\'s degree, 2014-18'], \n",
    "                                                                     x['Percent of adults with a bachelor\\'s degree or higher, 2014-18'], 3), axis=1)\n",
    "education_group_top4 = education.apply(lambda x: education_group_top(x['Percent of adults with less than a high school diploma, 2014-18'], \n",
    "                                                                     x['Percent of adults with a high school diploma only, 2014-18'], \n",
    "                                                                     x['Percent of adults completing some college or associate\\'s degree, 2014-18'], \n",
    "                                                                     x['Percent of adults with a bachelor\\'s degree or higher, 2014-18'], 4), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = pd.read_excel(\"final/co-est2019-annres.xlsx\")\n",
    "populations['county'] = populations['Geographic Area'].apply(lambda x: x.split(',')[0][1:])\n",
    "populations['state'] = populations['Geographic Area'].apply(lambda x: x.split(',')[1])\n",
    "population = populations['Census']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([state, county], axis=1)\n",
    "                    \n",
    "result['confirmed_cases'] = confirmed_cases\n",
    "result['deaths'] = deaths\n",
    "result['population'] = population\n",
    "result['days'] = case_days\n",
    "result['avearge_case'] = (100000.0) * confirmed_cases / case_days / population # Daily confirmed case per 100k people\n",
    "result['populationdensity'] = populationdensity_category\n",
    "result['toppest_ethnicity'] = ethnic_group_top1\n",
    "result['second_ethnicity'] = ethnic_group_top2\n",
    "result['third_ethnicity'] = ethnic_group_top3\n",
    "result['toppest_age_group'] = age_groups_top1\n",
    "result['second_age_group'] = age_groups_top2\n",
    "result['third_age_group'] = age_groups_top3\n",
    "result['fourth_age_group'] = age_groups_top4\n",
    "result['top_education'] = education_group_top1\n",
    "result['second_top_education'] = education_group_top2\n",
    "result['popdensity'] = prepandemic['popdensity_2018']\n",
    "result['precent_Hispanic'] = prepandemic['hispanic_2018'] \n",
    "result['precent_White'] = prepandemic['nhwhite_2018'] \n",
    "result['precent_Black'] = prepandemic['nhblack_2018'] \n",
    "result['precent_Idian'] = prepandemic['nhindian_2018'] \n",
    "result['precent_Asian'] = prepandemic['nhasian_2018'] \n",
    "result['precent_Hawaii'] = prepandemic['nhhawaii_2018']\n",
    "result['bachelor'] = education['Percent of adults with a bachelor\\'s degree or higher, 2014-18']\n",
    "result['college'] = education['Percent of adults completing some college or associate\\'s degree, 2014-18']\n",
    "result['highschool'] = education['Percent of adults with a high school diploma only, 2014-18']\n",
    "result['lessthanhighschool'] = education['Percent of adults with less than a high school diploma, 2014-18']\n",
    "result['precent_under_20'] = prepandemic['ageg1_2018'] + prepandemic['ageg2_2018'] + prepandemic['ageg3_2018'] + prepandemic['ageg4_2018']\n",
    "result['precent_20_to_40'] = prepandemic['ageg5_2018'] + prepandemic['ageg6_2018'] + prepandemic['ageg7_2018'] + prepandemic['ageg8_2018'] + prepandemic['ageg9_2018']\n",
    "result['precent_40_to_60'] = prepandemic['ageg10_2018'] + prepandemic['ageg11_2018'] + prepandemic['ageg12_2018'] + prepandemic['ageg13_2018']\n",
    "result['precent_above_60'] = prepandemic['ageg14_2018'] + prepandemic['ageg15_2018'] + prepandemic['ageg16_2018'] + prepandemic['ageg17_2018'] + prepandemic['ageg18_2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target is 5 groups, very low, low, medium, high and very high\n",
    "def target_group(rank, total):\n",
    "    if (rank < total / 5.0):\n",
    "        return \"Very_Low\"\n",
    "    if (rank < total * 2.0 / 5.0):\n",
    "        return \"Low\"\n",
    "    if (rank < total * 3.0 / 5.0):\n",
    "        return \"Medium\"\n",
    "    if (rank < total * 4.0 / 5.0):\n",
    "        return \"High\"\n",
    "    return \"Very_High\"\n",
    "\n",
    "# Binary Target only has low and high\n",
    "def binary_target_group(rank, total):\n",
    "    if (rank < total / 2.0):\n",
    "        return \"Low\"\n",
    "    return \"High\"\n",
    "\n",
    "total = len(result)\n",
    "\n",
    "result['target_rank'] = result['avearge_case'].rank().apply(lambda r: target_group(r, total))\n",
    "result['binary_target_rank'] = result['avearge_case'].rank().apply(lambda r: binary_target_group(r, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('final/model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = result['avearge_case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "populationdensity_onehot = label_encoder.fit_transform(populationdensity_category)\n",
    "ethnic_group_top1_onehot = label_encoder.fit_transform(ethnic_group_top1)\n",
    "ethnic_group_top2_onehot = label_encoder.fit_transform(ethnic_group_top2)\n",
    "ethnic_group_top3_onehot = label_encoder.fit_transform(ethnic_group_top3)\n",
    "\n",
    "age_groups_top1_onehot = label_encoder.fit_transform(age_groups_top1)\n",
    "age_groups_top2_onehot = label_encoder.fit_transform(age_groups_top2)\n",
    "age_groups_top3_onehot = label_encoder.fit_transform(age_groups_top3)\n",
    "age_groups_top4_onehot = label_encoder.fit_transform(age_groups_top4)\n",
    "education_group_top1_onehot = label_encoder.fit_transform(education_group_top1)\n",
    "education_group_top2_onehot = label_encoder.fit_transform(education_group_top2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-340fed69b446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    447\u001b[0m            \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mRandom\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbl\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPeredachi\u001b[0m \u001b[0mInf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1987\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \"\"\"\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[1;32m    451\u001b[0m                         copy, random_state)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "mutual_info_classif(X, y, discrete_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
